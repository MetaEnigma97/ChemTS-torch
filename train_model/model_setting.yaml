Data:
  dataset: ../data/250k_rndm_zinc_drugs_clean.smi
  format: smiles
  output_model_dir: pretrained/smiles_zinc250k
  output_token: pretrained/smiles_zinc250k/smiles_tokens.txt
  seq_len: 73
  vocab_len: 65
Model:
  dropout_rate: 0.2
  hidden_dim: 256
  n_layer: 2
Seed: 123
Train:
  accelerator: gpu
  batch_size: 512
  decay_alpha: 0.01
  decay_steps: 100
  device: 3
  epoch: 1000
  gradient_clip: 2.0
  learning_rate: 0.001
  num_workers: 12
  optimizer: adam
  patience: 50
  scheduler: CosineAnnealingLR
  validation_split: 0.1
